<<<<<<< HEAD

{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-25T22:29:34.006781+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:29:44.822084+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:29:47.206700+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:30:25.953224+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:30:27.505732+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.5 tokens", "timestamp": "2024-06-25T22:31:34.929998+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:31:36.457482+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-25T22:32:07.280049+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:32:11.080612+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:32:12.672975+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:33:19.815460+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:33:22.101853+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:33:58.263965+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:33:59.886687+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-25T22:34:27.133614+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:34:31.859104+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:34:35.628622+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-25T22:34:50.884283+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-25T22:34:55.254239+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:34:58.407526+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:35:00.104646+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:35:54.435485+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:35:56.214581+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-25T22:43:23.212595+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:43:41.941482+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:43:43.686081+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:45:06.579481+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:45:08.269862+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:48:01.800633+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:48:03.486683+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:48:50.053447+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:48:52.021272+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-25T22:51:34.928536+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:51:36.071446+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "400 Bad Request: The browser (or proxy) sent a request that this server could not understand.", "timestamp": "2024-06-25T22:54:00.814508+00:00", "logger": "__name__", "module": "routes", "function": "extractSpecificPatentMetrics", "line": 61, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2152.0 tokens", "timestamp": "2024-06-25T22:55:00.237921+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:55:02.185114+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 25310.25 tokens", "timestamp": "2024-06-25T22:56:53.065992+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "timestamp": "2024-06-25T22:56:53.928079+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20966 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "timestamp": "2024-06-25T22:56:53.928808+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 25313.25 tokens", "timestamp": "2024-06-25T22:57:46.630921+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "timestamp": "2024-06-25T22:57:47.073912+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20968 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "timestamp": "2024-06-25T22:57:47.074356+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 25310.25 tokens", "timestamp": "2024-06-25T22:58:20.995466+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "timestamp": "2024-06-25T22:58:21.685920+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20966 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "timestamp": "2024-06-25T22:58:21.686734+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3805.0 tokens", "timestamp": "2024-06-25T22:58:54.176150+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:58:55.994223+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 23636.0 tokens", "timestamp": "2024-06-25T22:58:59.876157+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "timestamp": "2024-06-25T22:59:00.496222+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 21290 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "timestamp": "2024-06-25T22:59:00.496698+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3836.0 tokens", "timestamp": "2024-06-25T22:59:20.242448+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:59:22.619272+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 17939.75 tokens", "timestamp": "2024-06-25T22:59:25.494508+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-25T22:59:39.306605+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-26T03:22:37.997950+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-26T03:29:31.851794+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-26T03:29:45.261736+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-26T03:29:49.209133+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-26T03:30:10.016047+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T03:32:21.353720+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T03:32:23.092383+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1850.75 tokens", "timestamp": "2024-06-26T03:32:36.269999+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T03:32:38.347042+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1968.0 tokens", "timestamp": "2024-06-26T03:32:45.379894+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T03:32:47.430254+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 7994.0 tokens", "timestamp": "2024-06-26T03:32:56.111689+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T03:33:19.618114+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T03:33:22.141302+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T03:33:24.016726+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3134.5 tokens", "timestamp": "2024-06-26T03:33:31.610441+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T03:33:34.053340+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-26T04:13:17.385569+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:13:20.226927+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:13:21.678693+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:14:30.206891+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:14:31.691846+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:17:42.633141+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:17:44.111796+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3270.5 tokens", "timestamp": "2024-06-26T04:17:49.078558+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:17:51.481281+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 16540.0 tokens", "timestamp": "2024-06-26T04:20:11.410289+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:20:21.399271+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2175.75 tokens", "timestamp": "2024-06-26T04:20:28.459047+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:20:30.612469+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3270.5 tokens", "timestamp": "2024-06-26T04:22:41.746448+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:22:44.065163+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:23:43.090329+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:23:44.667549+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1615.75 tokens", "timestamp": "2024-06-26T04:23:48.610466+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:23:51.321292+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:24:35.452363+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:24:37.048242+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2540.0 tokens", "timestamp": "2024-06-26T04:24:41.203708+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:24:43.442367+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2540.0 tokens", "timestamp": "2024-06-26T04:26:00.329586+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:26:02.843839+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:26:28.288334+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:26:29.842155+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1974.75 tokens", "timestamp": "2024-06-26T04:26:33.760196+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:26:35.572218+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1974.75 tokens", "timestamp": "2024-06-26T04:27:01.627554+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:27:04.448830+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1857.5 tokens", "timestamp": "2024-06-26T04:27:51.160000+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:27:53.700803+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1926.5 tokens", "timestamp": "2024-06-26T04:27:57.239556+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:27:59.335947+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1948.75 tokens", "timestamp": "2024-06-26T04:28:03.737505+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:28:06.007436+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 6609.0 tokens", "timestamp": "2024-06-26T04:28:26.263212+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:28:52.422104+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:29:38.389642+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:29:40.009858+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3022.0 tokens", "timestamp": "2024-06-26T04:29:47.024803+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:29:49.194935+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:30:31.258013+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:30:32.938178+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2992.75 tokens", "timestamp": "2024-06-26T04:30:38.011856+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:30:40.622571+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2992.75 tokens", "timestamp": "2024-06-26T04:31:09.558996+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:31:11.884166+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2992.75 tokens", "timestamp": "2024-06-26T04:31:24.937852+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:31:27.882173+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:32:15.636775+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:32:17.065938+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1940.0 tokens", "timestamp": "2024-06-26T04:32:20.971205+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:32:22.820791+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1816.5 tokens", "timestamp": "2024-06-26T04:32:57.611215+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:32:59.887474+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3962.25 tokens", "timestamp": "2024-06-26T04:33:11.415643+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:33:13.957772+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1966.0 tokens", "timestamp": "2024-06-26T04:35:12.796595+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:35:14.853663+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:35:50.215673+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:35:51.363432+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3134.0 tokens", "timestamp": "2024-06-26T04:35:54.929637+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:35:56.885855+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2648.75 tokens", "timestamp": "2024-06-26T04:36:26.782218+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:36:29.300484+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2168.0 tokens", "timestamp": "2024-06-26T04:36:56.473803+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:36:58.586228+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:37:19.226547+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:37:20.808260+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3015.25 tokens", "timestamp": "2024-06-26T04:37:25.101667+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:37:27.259439+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2539.0 tokens", "timestamp": "2024-06-26T04:38:39.758121+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:38:41.613020+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:44:04.004154+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:44:05.890816+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:44:24.420768+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:44:25.836892+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1619.25 tokens", "timestamp": "2024-06-26T04:44:31.371347+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:44:33.749323+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1890.0 tokens", "timestamp": "2024-06-26T04:44:34.386865+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:44:36.423135+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 4168.25 tokens", "timestamp": "2024-06-26T04:44:38.982672+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:44:41.543414+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-26T04:44:47.019261+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:44:48.892339+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3281.5 tokens", "timestamp": "2024-06-26T04:44:52.151816+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:44:54.193203+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 16541.0 tokens", "timestamp": "2024-06-26T04:44:58.399609+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:45:11.050501+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 16544.75 tokens", "timestamp": "2024-06-26T04:45:11.637005+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-26T04:45:22.129568+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T03:53:19.976993+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T03:53:21.639545+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1853.0 tokens", "timestamp": "2024-06-27T03:53:28.524935+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T03:53:31.258887+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T03:56:34.451165+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T03:56:35.998603+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T03:56:54.391076+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T03:56:55.775112+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1957.25 tokens", "timestamp": "2024-06-27T03:57:59.876354+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T03:58:01.916865+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:37:58.700459+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:38:00.448399+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2993.75 tokens", "timestamp": "2024-06-27T06:38:05.199349+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:38:07.979146+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 14293.75 tokens", "timestamp": "2024-06-27T06:38:11.574473+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:38:22.618324+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 14295.75 tokens", "timestamp": "2024-06-27T06:41:00.146734+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:41:20.394315+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 14295.25 tokens", "timestamp": "2024-06-27T06:41:59.627056+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:42:17.731720+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 14295.5 tokens", "timestamp": "2024-06-27T06:42:27.370363+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:42:51.932310+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:42:51.987235+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:42:53.902709+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3060.0 tokens", "timestamp": "2024-06-27T06:43:02.116732+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:43:04.717699+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 24982.0 tokens", "timestamp": "2024-06-27T06:43:12.027102+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "timestamp": "2024-06-27T06:43:12.718061+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 22611 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "timestamp": "2024-06-27T06:43:12.721577+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 24983.25 tokens", "timestamp": "2024-06-27T06:43:50.519445+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "timestamp": "2024-06-27T06:43:51.016821+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 22611 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "timestamp": "2024-06-27T06:43:51.018575+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:44:15.217464+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:44:16.821989+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:44:36.390668+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:44:38.017463+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1868.0 tokens", "timestamp": "2024-06-27T06:44:42.934374+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:44:45.183084+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 9224.5 tokens", "timestamp": "2024-06-27T06:44:48.365083+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:45:06.668852+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:45:06.726758+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:45:08.140856+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1853.75 tokens", "timestamp": "2024-06-27T06:45:17.946374+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:45:20.347581+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 9222.5 tokens", "timestamp": "2024-06-27T06:45:24.016116+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:45:42.319752+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 9224.0 tokens", "timestamp": "2024-06-27T06:46:22.265780+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:46:35.576752+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2539.25 tokens", "timestamp": "2024-06-27T06:47:36.821392+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:47:39.345737+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:47:47.804825+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:47:49.783510+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:48:09.864138+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:48:11.414984+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:49:00.371465+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:49:02.208309+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:49:16.576920+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:49:18.693215+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:49:27.950930+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:49:29.650928+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:50:01.534113+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:50:03.020307+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2999.0 tokens", "timestamp": "2024-06-27T06:50:08.293501+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:50:10.712619+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 14293.75 tokens", "timestamp": "2024-06-27T06:50:13.957868+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:50:31.304158+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:50:45.694217+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:50:47.477516+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:51:07.719928+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:51:10.309390+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1972.25 tokens", "timestamp": "2024-06-27T06:51:18.581626+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:51:21.266977+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 6607.75 tokens", "timestamp": "2024-06-27T06:51:24.862871+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:51:50.069046+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 6615.5 tokens", "timestamp": "2024-06-27T06:51:50.518839+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:52:15.680004+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 6613.25 tokens", "timestamp": "2024-06-27T06:52:16.187976+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:52:35.199397+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 6613.5 tokens", "timestamp": "2024-06-27T06:52:35.662596+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:52:44.740584+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 6614.75 tokens", "timestamp": "2024-06-27T06:53:05.939741+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:53:25.683328+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:53:29.288057+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:53:30.595323+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3133.5 tokens", "timestamp": "2024-06-27T06:53:38.298569+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:53:40.626953+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:54:17.412983+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:54:18.827287+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3797.0 tokens", "timestamp": "2024-06-27T06:54:29.121159+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:54:31.716724+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 23632.75 tokens", "timestamp": "2024-06-27T06:54:39.429915+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "timestamp": "2024-06-27T06:54:39.816890+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 21289 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "timestamp": "2024-06-27T06:54:39.819382+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 23632.25 tokens", "timestamp": "2024-06-27T06:55:35.213288+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "timestamp": "2024-06-27T06:55:35.863045+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 21288 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "timestamp": "2024-06-27T06:55:35.864535+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2318.75 tokens", "timestamp": "2024-06-27T06:55:43.329026+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:55:46.247796+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 23633.0 tokens", "timestamp": "2024-06-27T06:55:48.575473+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "timestamp": "2024-06-27T06:55:49.144996+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 21289 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "timestamp": "2024-06-27T06:55:49.146097+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 23632.75 tokens", "timestamp": "2024-06-27T06:55:50.943312+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "timestamp": "2024-06-27T06:55:51.560726+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 21289 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}", "timestamp": "2024-06-27T06:55:51.561967+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:56:10.316792+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:56:11.670539+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2404.25 tokens", "timestamp": "2024-06-27T06:56:21.235763+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:56:23.305447+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 8679.5 tokens", "timestamp": "2024-06-27T06:56:26.986577+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T06:57:00.704349+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 8681.25 tokens", "timestamp": "2024-06-27T06:58:44.271915+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T06:58:51.451135+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 8680.75 tokens", "timestamp": "2024-06-27T06:58:53.646713+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:59:21.010465+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-27T06:59:21.096058+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T06:59:22.545039+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
=======
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T20:41:43.202542+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T20:42:00.951100+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T20:50:18.875513+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-27T20:51:18.844091+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T20:51:20.565154+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T20:51:31.230047+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T21:17:01.957285+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-27T21:31:15.733707+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T21:31:18.292813+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T21:31:31.580378+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T21:31:36.721960+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-27T23:52:30.896753+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T23:52:32.411310+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T00:37:07.420235+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:37:09.147676+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T00:39:43.391597+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:39:44.792127+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 846.75 tokens", "timestamp": "2024-06-28T00:39:50.930458+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:39:54.310766+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1759.5 tokens", "timestamp": "2024-06-28T00:39:57.822161+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:39:59.741839+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 9117.25 tokens", "timestamp": "2024-06-28T00:40:04.040772+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:40:31.387663+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
>>>>>>> development
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T02:38:52.614785+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T03:39:56.486373+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.5 tokens", "timestamp": "2024-06-28T03:41:40.083205+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:41:41.560538+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2118.0 tokens", "timestamp": "2024-06-28T03:41:45.864333+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:41:47.974835+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1638.75 tokens", "timestamp": "2024-06-28T03:43:32.121092+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:43:35.930289+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1638.75 tokens", "timestamp": "2024-06-28T03:43:36.381246+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:43:38.565942+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-28T03:43:56.503032+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:43:58.327957+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1858.0 tokens", "timestamp": "2024-06-28T03:44:01.409792+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:44:03.447718+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 9222.0 tokens", "timestamp": "2024-06-28T03:44:12.085471+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:44:22.802020+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1975.25 tokens", "timestamp": "2024-06-28T03:44:23.321088+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:44:25.258449+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 7993.5 tokens", "timestamp": "2024-06-28T03:44:37.753823+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:44:54.439378+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Failed to parse JSON from completion: Failed to parse CitationsExtraction from completion {\"claims\": [{\"before\": \"An espresso coffee machine comprising: a water feeding hydraulic circuit; at least one boiler for heating the water, located downstream of said water feeding hydraulic circuit; a coffee dispenser unit, located downstream of said boiler and provided with at least one coffee panel configured for mixing hot water with coffee; and a first pumping hydraulic circuit, provided with at least one pump for water, interposed between said water feeding hydraulic circuit and said boiler, the espresso coffee machine being characterized in that a second pumping hydraulic circuit is interposed between the water feeding hydraulic circuit and the boiler, said second pumping hydraulic circuit being connected in parallel with the first pumping hydraulic circuit and being provided with a lever pumping unit, wherein said lever pumping unit works at room temperature, being physically separated from both the boiler and from the coffee dispenser unit.\", \"highlight\": \"This innovative coffee machine features an integrated grinder and brewing system, allowing users to grind fresh coffee beans immediately before brewing.\", \"after\": \"The machine includes an intuitive touch screen interface for easy operation, programmable settings for customizing brew strength and volume, and a built-in milk frother for creating various coffee beverages such as lattes and cappuccinos.\"}, {\"before\": \"The espresso coffee machine according to claim 1 , wherein the lever pumping unit is provided with at least one pumping piston manually operated by a lever, wherein said pumping piston is configured for pumping water coming from the water feeding hydraulic circuit.\", \"highlight\": \"The espresso coffee machine according to claim 2 , wherein the lever actuates the pumping piston through the interposition of one or more springs with adjustable load, so as to obtain different curves and profiles of water pressure according to the needs.\", \"after\": \"The espresso coffee machine according to claim 1 , wherein the pump is a rotative pump.\"}], \"abstract\": [{\"before\": \"Described herein is an espresso coffee machine having a water feeding hydraulic circuit, at least one boiler for heating water, located downstream of the water feeding hydraulic circuit, a coffee dispenser unit, located downstream of the boiler and provided with at least one coffee panel configured for mixing hot water with coffee, and a first pumping hydraulic circuit, provided with at least one pump for the water and interposed between the water feeding hydraulic circuit and the boiler.\", \"highlight\": \"The present invention relates in general to an espresso coffee machine and, in particular, to an espresso coffee machine able to combine the technical features of a so-called lever coffee machine and of a so-called traditional coffee machine.\", \"after\": \"As is well known, an espresso coffee machine is an instrument that makes it possible to prepare the drink known as espresso coffee and its derivatives (cappuccino, macchiato, infusions, etc.).\"}], \"description\": [{\"before\": \"Traditional machines, introduced on the market towards the end of the Forties of the past century, characterised an important historical phase of espresso coffee machines. A typical lever machine, shown schematically in FIG. 1 , comprises mainly a mechanical system consisting of a lever 110 , a spring 120 and a dispenser set 130 . Lever machines have the merit of being very quiet, because they do not use any pump.\", \"highlight\": \"The main defects of lever machines are due to the temperature and volume of the water. Regulating temperature is very difficult. A long time is required to bring the dispenser set 130 to its operating temperature, given its considerable mass.\", \"after\": \"To utilise a lever machine correctly it is necessary to have highly qualified, experienced personnel available.\"}, {\"before\": \"Subsequently, dedicated boilers were realised for each service, i.e. a first boiler arranged to manage the dispensing of coffee and a second boiler arranged to manage the delivery of hot water and steam. In this way it is possible to regulate the temperatures of the two boilers distinctly and, consequently, to set the boiler of the coffee to the desired temperature through the most advanced temperature control systems (for example proportional-integral-derivative's or PID's type).\", \"highlight\": \"Through the years, the temperature regulating system of traditional coffee machines has undergone considerable innovations.\", \"after\": \"Use of traditional coffee machines is very simple, safe and intuitive, but they are markedly noisier machines than lever machines.\"}, {\"before\": \"The combined espresso coffee machine according to the present invention thus conceived is susceptible in every case to many modifications and variants, all falling within the same inventive concept; furthermore, all details can be replaced by equivalent technical elements.\", \"highlight\": \"The scope of protection of the invention is therefore defined by the appended claims.\", \"after\": \"\"}]}. Got: 1 validation error for CitationsExtraction\ndescription -> 2 -> __root__\n  Before, highlight and after must contain text. (type=value_error)", "timestamp": "2024-06-28T03:44:54.491545+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 79, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1063.5 tokens", "timestamp": "2024-06-28T03:44:54.890722+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:45:01.406875+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 7996.0 tokens", "timestamp": "2024-06-28T03:45:42.114779+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:46:00.285930+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-28T03:46:06.174104+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:46:07.662064+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2485.5 tokens", "timestamp": "2024-06-28T03:46:11.741142+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:46:13.803398+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 11894.5 tokens", "timestamp": "2024-06-28T03:46:18.402827+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:46:34.293074+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-28T03:51:19.058131+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:51:20.294194+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2534.25 tokens", "timestamp": "2024-06-28T03:51:33.611869+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:51:35.813808+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1591.75 tokens", "timestamp": "2024-06-28T03:52:19.697324+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:52:22.981037+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-28T03:54:18.713401+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:54:20.098496+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1625.5 tokens", "timestamp": "2024-06-28T03:55:01.862029+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:55:05.279361+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 16258.5 tokens", "timestamp": "2024-06-28T03:55:09.147638+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:55:33.039987+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 704.5 tokens", "timestamp": "2024-06-28T03:55:39.570181+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T03:55:42.616394+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-28T04:04:35.406970+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:04:36.684304+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3010.5 tokens", "timestamp": "2024-06-28T04:04:41.916484+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:04:44.067981+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2047.25 tokens", "timestamp": "2024-06-28T04:04:44.577669+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:04:48.839260+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-28T04:06:38.012041+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:06:39.156672+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-28T04:06:39.168603+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:06:40.689913+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2157.5 tokens", "timestamp": "2024-06-28T04:06:43.084756+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:06:45.288346+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-28T04:07:12.972258+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:07:14.379941+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3010.0 tokens", "timestamp": "2024-06-28T04:08:00.331476+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:08:02.306932+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 13602.75 tokens", "timestamp": "2024-06-28T04:08:08.406756+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:08:16.844164+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2047.25 tokens", "timestamp": "2024-06-28T04:08:17.290319+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:08:21.349005+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T04:41:38.787105+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-28T04:42:11.199147+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:42:12.566561+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2403.0 tokens", "timestamp": "2024-06-28T04:42:18.343990+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:42:20.551773+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1530.75 tokens", "timestamp": "2024-06-28T04:42:23.659900+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:42:28.381425+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 8679.5 tokens", "timestamp": "2024-06-28T04:46:07.046632+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:46:23.544609+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.5 tokens", "timestamp": "2024-06-28T04:48:06.126067+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:48:07.515006+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3818.25 tokens", "timestamp": "2024-06-28T04:48:11.367743+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:48:13.290066+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 17935.0 tokens", "timestamp": "2024-06-28T04:48:18.014086+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:48:24.765547+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 17936.0 tokens", "timestamp": "2024-06-28T04:53:20.872134+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:53:34.609764+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 5626.25 tokens", "timestamp": "2024-06-28T04:54:05.878343+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:54:08.186339+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 13604.5 tokens", "timestamp": "2024-06-28T04:58:00.483777+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:58:28.403931+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 13604.5 tokens", "timestamp": "2024-06-28T04:58:28.868526+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T04:58:45.399640+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-28T05:01:43.812364+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T05:01:45.336552+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2047.25 tokens", "timestamp": "2024-06-28T05:02:05.510154+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T05:02:13.106909+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3020.0 tokens", "timestamp": "2024-06-28T05:05:41.620318+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T05:05:43.629141+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
