<<<<<<< HEAD
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T20:41:43.202542+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T20:42:00.951100+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T20:50:18.875513+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-27T20:51:18.844091+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T20:51:20.565154+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T20:51:31.230047+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T21:17:01.957285+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-27T21:31:15.733707+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T21:31:18.292813+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T21:31:31.580378+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-27T21:31:36.721960+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-27T23:52:30.896753+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-27T23:52:32.411310+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T00:37:07.420235+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:37:09.147676+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T00:39:43.391597+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:39:44.792127+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 846.75 tokens", "timestamp": "2024-06-28T00:39:50.930458+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:39:54.310766+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1759.5 tokens", "timestamp": "2024-06-28T00:39:57.822161+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:39:59.741839+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 9117.25 tokens", "timestamp": "2024-06-28T00:40:04.040772+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:40:31.387663+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T00:59:57.093257+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T00:59:58.650870+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T01:06:28.876910+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T01:06:59.220596+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T01:07:26.963449+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T02:17:15.783987+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T02:17:17.204866+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T02:18:48.980985+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T02:18:50.447464+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T02:19:41.050521+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T02:19:42.326626+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 827.25 tokens", "timestamp": "2024-06-28T02:21:05.406314+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T02:21:08.968927+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T02:25:46.018202+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T02:25:47.463207+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T02:27:31.102052+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T02:27:38.813744+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T15:08:27.637518+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:04:17.994964+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:06:07.447773+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 883, in full_dispatch_request\n    return self.finalize_request(rv)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 902, in finalize_request\n    response = self.make_response(rv)\n               ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1211, in make_response\n    raise TypeError(\nTypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a int.", "timestamp": "2024-06-28T16:06:07.736382+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:06:52.814380+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:07:05.506832+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 883, in full_dispatch_request\n    return self.finalize_request(rv)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 902, in finalize_request\n    response = self.make_response(rv)\n               ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1211, in make_response\n    raise TypeError(\nTypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a int.", "timestamp": "2024-06-28T16:07:07.037490+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:07:57.021264+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 883, in full_dispatch_request\n    return self.finalize_request(rv)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 902, in finalize_request\n    response = self.make_response(rv)\n               ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1211, in make_response\n    raise TypeError(\nTypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a int.", "timestamp": "2024-06-28T16:07:57.799280+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:08:19.928475+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 883, in full_dispatch_request\n    return self.finalize_request(rv)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 902, in finalize_request\n    response = self.make_response(rv)\n               ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1211, in make_response\n    raise TypeError(\nTypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a int.", "timestamp": "2024-06-28T16:08:20.393204+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:08:31.440651+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:13:42.852857+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:13:49.258661+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 62, in getPatentsByIDs\n    results = response.json().get(\"results\")  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T16:13:51.835652+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:14:06.138738+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 883, in full_dispatch_request\n    return self.finalize_request(rv)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 902, in finalize_request\n    response = self.make_response(rv)\n               ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1211, in make_response\n    raise TypeError(\nTypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a int.", "timestamp": "2024-06-28T16:14:06.339746+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:14:16.617695+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 883, in full_dispatch_request\n    return self.finalize_request(rv)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 902, in finalize_request\n    response = self.make_response(rv)\n               ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1211, in make_response\n    raise TypeError(\nTypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a int.", "timestamp": "2024-06-28T16:14:16.813545+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:19:02.350161+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 883, in full_dispatch_request\n    return self.finalize_request(rv)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 902, in finalize_request\n    response = self.make_response(rv)\n               ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1211, in make_response\n    raise TypeError(\nTypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a Response.", "timestamp": "2024-06-28T16:19:02.546324+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:19:13.010024+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 883, in full_dispatch_request\n    return self.finalize_request(rv)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 902, in finalize_request\n    response = self.make_response(rv)\n               ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1211, in make_response\n    raise TypeError(\nTypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a Response.", "timestamp": "2024-06-28T16:19:13.857516+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:19:40.033518+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:25:10.276034+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 63, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T16:25:10.608084+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:25:23.946625+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:39:38.267376+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 63, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T16:39:38.360845+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T16:39:50.890755+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:10:56.526434+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:13:03.283452+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:13:22.153861+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:13:37.914807+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:15:03.625538+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:15:40.859261+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T17:15:40.876454+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T17:15:42.348099+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "PatentScraper.getSection() missing 1 required positional argument: 'field'", "timestamp": "2024-06-28T17:15:48.115977+00:00", "logger": "__name__", "module": "routes", "function": "extractSpecificPatentMetrics", "line": 61, "thread_name": "MainThread"}
{"level": "ERROR", "message": "PatentScraper.getSection() missing 1 required positional argument: 'field'", "timestamp": "2024-06-28T17:15:51.096358+00:00", "logger": "__name__", "module": "routes", "function": "extractSpecificPatentMetrics", "line": 61, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:16:53.556088+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:17:00.798530+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 35, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1260.5 tokens", "timestamp": "2024-06-28T17:17:00.800432+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T17:17:03.433546+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:17:12.344223+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:17:18.784776+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:17:21.855916+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 35, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1260.5 tokens", "timestamp": "2024-06-28T17:17:21.857107+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T17:17:23.821896+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:18:08.190454+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:18:09.194178+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 35, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1260.5 tokens", "timestamp": "2024-06-28T17:18:09.196170+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T17:18:11.642191+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:19:05.242465+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:19:08.604679+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:19:11.687909+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 37, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1260.5 tokens", "timestamp": "2024-06-28T17:19:11.689753+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T17:19:15.438408+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:19:34.592405+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:19:36.664922+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 38, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1260.5 tokens", "timestamp": "2024-06-28T17:19:36.666021+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T17:19:38.886622+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:19:55.669038+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:19:59.925210+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 37, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1260.5 tokens", "timestamp": "2024-06-28T17:19:59.926903+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T17:20:02.137691+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:20:14.465504+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:20:32.779283+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 38, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1260.5 tokens", "timestamp": "2024-06-28T17:20:32.781472+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T17:20:35.209158+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:21:32.157906+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 64, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:21:36.503985+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:21:46.708483+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 64, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:21:46.810667+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:21:51.259710+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:22:39.738680+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 63, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:22:40.720214+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:22:47.117128+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:23:05.980363+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 63, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:23:06.081042+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:23:12.390378+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 63, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:23:12.473052+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:23:16.741403+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:23:23.246344+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 63, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:23:23.334186+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:24:26.003163+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 63, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:24:26.103521+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:24:43.635142+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 62, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:24:43.737670+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:24:48.020315+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:25:09.965806+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 62, in getPatentsByIDs\n    results = response.json()  # decode response\n              ^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/requests/models.py\", line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "timestamp": "2024-06-28T17:25:10.060297+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:25:20.420396+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:26:31.893775+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:26:46.664280+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:27:05.480029+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "'list' object has no attribute 'join'", "timestamp": "2024-06-28T17:27:08.214119+00:00", "logger": "__name__", "module": "routes", "function": "extractSpecificPatentMetrics", "line": 61, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:27:44.692646+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "'dict' object has no attribute 'claims'", "timestamp": "2024-06-28T17:27:44.869564+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 36, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1260.5 tokens", "timestamp": "2024-06-28T17:27:44.870666+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T17:27:47.332972+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T17:27:54.286902+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "'list' object has no attribute 'join'", "timestamp": "2024-06-28T17:27:55.341558+00:00", "logger": "__name__", "module": "routes", "function": "extractSpecificPatentMetrics", "line": 61, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:07:03.765413+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "'list' object has no attribute 'join'", "timestamp": "2024-06-28T18:07:06.395307+00:00", "logger": "__name__", "module": "routes", "function": "extractSpecificPatentMetrics", "line": 61, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:09:51.124986+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1263.25 tokens", "timestamp": "2024-06-28T18:09:52.020688+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T18:09:54.193374+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:10:01.811000+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-28T18:10:07.596172+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T18:10:09.170369+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2263.25 tokens", "timestamp": "2024-06-28T18:10:12.309290+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T18:10:14.591335+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:10:39.633236+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:23:50.872979+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:24:05.691160+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:24:16.103265+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:24:48.067867+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3206.5 tokens", "timestamp": "2024-06-28T18:24:49.277077+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T18:24:51.531784+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:31:06.547423+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:31:20.059885+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:32:58.947393+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:34:23.771983+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:34:29.102666+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:35:05.176446+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:36:41.989919+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 55, in getPatentsByIDs\n    response = PatentRetrievalFactory.getHandler(data, PatentRetrievalFactory.RequestType.ID)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/factory.py\", line 17, in getHandler\n    raise ValueError(\"not a valid request\")\nValueError: not a valid request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 59, in getPatentsByIDs\n    return jsonify({\"error\": e}), 400\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/__init__.py\", line 170, in jsonify\n    return current_app.json.response(*args, **kwargs)  # type: ignore[return-value]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 214, in response\n    f\"{self.dumps(obj, **dump_args)}\\n\", mimetype=self.mimetype\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 179, in dumps\n    return json.dumps(obj, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 238, in dumps\n    **kw).encode(obj)\n          ^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py\", line 200, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py\", line 258, in iterencode\n    return _iterencode(o, 0)\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 121, in _default\n    raise TypeError(f\"Object of type {type(o).__name__} is not JSON serializable\")\nTypeError: Object of type ValueError is not JSON serializable", "timestamp": "2024-06-28T18:37:08.133840+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:37:26.279887+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 55, in getPatentsByIDs\n    response = PatentRetrievalFactory.getHandler(data, PatentRetrievalFactory.RequestType.ID)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/factory.py\", line 17, in getHandler\n    raise ValueError(\"not a valid request\")\nValueError: not a valid request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 59, in getPatentsByIDs\n    return jsonify({\"error\": e}), 400\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/__init__.py\", line 170, in jsonify\n    return current_app.json.response(*args, **kwargs)  # type: ignore[return-value]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 214, in response\n    f\"{self.dumps(obj, **dump_args)}\\n\", mimetype=self.mimetype\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 179, in dumps\n    return json.dumps(obj, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 238, in dumps\n    **kw).encode(obj)\n          ^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py\", line 200, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py\", line 258, in iterencode\n    return _iterencode(o, 0)\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 121, in _default\n    raise TypeError(f\"Object of type {type(o).__name__} is not JSON serializable\")\nTypeError: Object of type ValueError is not JSON serializable", "timestamp": "2024-06-28T18:37:28.476609+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:37:36.886376+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 55, in getPatentsByIDs\n    response = PatentRetrievalFactory.getHandler(data, PatentRetrievalFactory.RequestType.ID)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/factory.py\", line 17, in getHandler\n    raise ValueError(\"not a valid request\")\nValueError: not a valid request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 59, in getPatentsByIDs\n    return jsonify({\"error\": e}), 400\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/__init__.py\", line 170, in jsonify\n    return current_app.json.response(*args, **kwargs)  # type: ignore[return-value]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 214, in response\n    f\"{self.dumps(obj, **dump_args)}\\n\", mimetype=self.mimetype\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 179, in dumps\n    return json.dumps(obj, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 238, in dumps\n    **kw).encode(obj)\n          ^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py\", line 200, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py\", line 258, in iterencode\n    return _iterencode(o, 0)\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 121, in _default\n    raise TypeError(f\"Object of type {type(o).__name__} is not JSON serializable\")\nTypeError: Object of type ValueError is not JSON serializable", "timestamp": "2024-06-28T18:37:36.892662+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:38:01.698385+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:38:04.032415+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 55, in getPatentsByIDs\n    response = PatentRetrievalFactory.getHandler(data, PatentRetrievalFactory.RequestType.ID)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/factory.py\", line 17, in getHandler\n    raise ValueError(\"not a valid request\")\nValueError: not a valid request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 59, in getPatentsByIDs\n    return jsonify({\"error\": e}), 400\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/__init__.py\", line 170, in jsonify\n    return current_app.json.response(*args, **kwargs)  # type: ignore[return-value]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 214, in response\n    f\"{self.dumps(obj, **dump_args)}\\n\", mimetype=self.mimetype\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 179, in dumps\n    return json.dumps(obj, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 238, in dumps\n    **kw).encode(obj)\n          ^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py\", line 200, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py\", line 258, in iterencode\n    return _iterencode(o, 0)\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 121, in _default\n    raise TypeError(f\"Object of type {type(o).__name__} is not JSON serializable\")\nTypeError: Object of type ValueError is not JSON serializable", "timestamp": "2024-06-28T18:38:04.038205+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:38:09.488144+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /patents/getPatentsByIDs [POST]\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 55, in getPatentsByIDs\n    response = PatentRetrievalFactory.getHandler(data, PatentRetrievalFactory.RequestType.ID)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/factory.py\", line 17, in getHandler\n    raise ValueError(\"not a valid request\")\nValueError: not a valid request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/app/blueprints/patentRetrieval/routes.py\", line 59, in getPatentsByIDs\n    return jsonify({\"error\": e}), 400\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/__init__.py\", line 170, in jsonify\n    return current_app.json.response(*args, **kwargs)  # type: ignore[return-value]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 214, in response\n    f\"{self.dumps(obj, **dump_args)}\\n\", mimetype=self.mimetype\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 179, in dumps\n    return json.dumps(obj, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py\", line 238, in dumps\n    **kw).encode(obj)\n          ^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py\", line 200, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py\", line 258, in iterencode\n    return _iterencode(o, 0)\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/alecpalo/Projects/DulanyAI/backend/env/lib/python3.12/site-packages/flask/json/provider.py\", line 121, in _default\n    raise TypeError(f\"Object of type {type(o).__name__} is not JSON serializable\")\nTypeError: Object of type ValueError is not JSON serializable", "timestamp": "2024-06-28T18:38:09.494316+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:38:59.766275+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "", "timestamp": "2024-06-28T18:39:00.095692+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 35, "thread_name": "MainThread"}
{"level": "ERROR", "message": "", "timestamp": "2024-06-28T18:39:00.205056+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 35, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 148.0 tokens", "timestamp": "2024-06-28T18:39:00.207615+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T18:39:04.428802+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:39:17.622576+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:39:31.247135+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "", "timestamp": "2024-06-28T18:39:36.228021+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 35, "thread_name": "MainThread"}
{"level": "ERROR", "message": "", "timestamp": "2024-06-28T18:39:36.310136+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 35, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 148.0 tokens", "timestamp": "2024-06-28T18:39:36.312742+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T18:39:40.680219+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:40:10.466924+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:40:17.861425+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:41:08.387844+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:41:13.909591+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "", "timestamp": "2024-06-28T18:41:14.290459+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 35, "thread_name": "MainThread"}
{"level": "ERROR", "message": "", "timestamp": "2024-06-28T18:41:15.413441+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 35, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 148.0 tokens", "timestamp": "2024-06-28T18:41:15.415700+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T18:41:20.535017+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:41:22.046623+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "", "timestamp": "2024-06-28T18:41:25.365519+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 34, "thread_name": "MainThread"}
{"level": "ERROR", "message": "", "timestamp": "2024-06-28T18:41:25.470678+00:00", "logger": "__name__", "module": "scraping", "function": "getSection", "line": 34, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 148.0 tokens", "timestamp": "2024-06-28T18:41:25.477900+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T18:41:28.214326+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:42:10.394408+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 801.5 tokens", "timestamp": "2024-06-28T18:42:13.632746+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-28T18:42:17.787806+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:42:45.440279+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-28T18:45:53.485738+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T15:33:19.622274+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 545.75 tokens", "timestamp": "2024-06-29T15:34:49.557303+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:34:50.870399+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T15:35:10.731141+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3814.25 tokens", "timestamp": "2024-06-29T15:35:11.040922+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:35:13.001182+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T15:35:52.493024+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2310.25 tokens", "timestamp": "2024-06-29T15:35:52.766795+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:35:55.122260+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T15:36:41.311314+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2209.0 tokens", "timestamp": "2024-06-29T15:36:43.452376+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:36:45.463818+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1761, 'output_tokens': 115, 'total_tokens': 1876}", "timestamp": "2024-06-29T15:36:45.472053+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 605.25 tokens", "timestamp": "2024-06-29T15:49:44.618675+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:49:46.247042+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 484, 'output_tokens': 106, 'total_tokens': 590}", "timestamp": "2024-06-29T15:49:46.254646+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3703.25 tokens", "timestamp": "2024-06-29T15:49:51.096911+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:49:53.548042+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 3450, 'output_tokens': 155, 'total_tokens': 3605}", "timestamp": "2024-06-29T15:49:53.553127+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2495.0 tokens", "timestamp": "2024-06-29T15:49:55.578890+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:49:59.593396+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2450, 'output_tokens': 266, 'total_tokens': 2716}", "timestamp": "2024-06-29T15:49:59.605987+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 5634.25 tokens", "timestamp": "2024-06-29T15:50:03.347548+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:50:08.972715+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 4672, 'output_tokens': 425, 'total_tokens': 5097}", "timestamp": "2024-06-29T15:50:08.978832+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 5631.25 tokens", "timestamp": "2024-06-29T15:50:48.552007+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:50:54.215820+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 4667, 'output_tokens': 501, 'total_tokens': 5168}", "timestamp": "2024-06-29T15:50:54.233059+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T15:51:55.426784+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 5629.5 tokens", "timestamp": "2024-06-29T15:51:58.961603+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:52:03.495803+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 4665, 'output_tokens': 357, 'total_tokens': 5022}", "timestamp": "2024-06-29T15:52:03.508643+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T15:52:05.586868+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 5630.75 tokens", "timestamp": "2024-06-29T15:52:24.217342+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T15:52:31.748111+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 4666, 'output_tokens': 568, 'total_tokens': 5234}", "timestamp": "2024-06-29T15:52:31.771959+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T15:52:42.192271+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 60873.25 tokens", "timestamp": "2024-06-29T15:52:45.768987+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T15:52:46.297189+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.799059 seconds", "timestamp": "2024-06-29T15:52:46.298064+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T15:52:47.388769+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.671951 seconds", "timestamp": "2024-06-29T15:52:47.389180+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T15:52:49.470008+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-3.5-turbo in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 60000, Requested 61279. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T15:52:49.472035+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T15:53:05.690013+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T15:57:59.281982+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T15:58:10.441346+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 60867.25 tokens", "timestamp": "2024-06-29T15:58:16.962855+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T15:58:17.517003+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.924872 seconds", "timestamp": "2024-06-29T15:58:17.517978+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T15:58:18.744768+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.506605 seconds", "timestamp": "2024-06-29T15:58:18.746162+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T15:58:20.515056+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 61273. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T15:58:20.519940+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T16:09:58.596134+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 605.25 tokens", "timestamp": "2024-06-29T16:10:12.558779+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:10:14.407643+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 479, 'output_tokens': 89, 'total_tokens': 568}", "timestamp": "2024-06-29T16:10:14.422723+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3686.75 tokens", "timestamp": "2024-06-29T16:10:24.730203+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:10:26.816112+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 3423, 'output_tokens': 137, 'total_tokens': 3560}", "timestamp": "2024-06-29T16:10:26.823101+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 60865.0 tokens", "timestamp": "2024-06-29T16:10:30.233756+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:10:30.612703+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.937407 seconds", "timestamp": "2024-06-29T16:10:30.615177+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:10:31.815002+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.865739 seconds", "timestamp": "2024-06-29T16:10:31.815827+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:10:34.046253+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 61271. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T16:10:34.046991+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T16:11:12.034125+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 60865.75 tokens", "timestamp": "2024-06-29T16:11:15.525523+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:11:16.024721+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.945459 seconds", "timestamp": "2024-06-29T16:11:16.025699+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:11:17.242838+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.910175 seconds", "timestamp": "2024-06-29T16:11:17.243205+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:11:19.426687+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 61271. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T16:11:19.428804+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T16:12:20.171600+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2200.0 tokens", "timestamp": "2024-06-29T16:12:33.461721+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:12:35.771023+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2088, 'output_tokens': 137, 'total_tokens': 2225}", "timestamp": "2024-06-29T16:12:35.779594+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1123.5 tokens", "timestamp": "2024-06-29T16:12:54.473049+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:13:00.245648+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1211, 'output_tokens': 363, 'total_tokens': 1574}", "timestamp": "2024-06-29T16:13:00.257736+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 36776.75 tokens", "timestamp": "2024-06-29T16:13:03.247723+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:13:03.628222+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.856262 seconds", "timestamp": "2024-06-29T16:13:03.630189+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:13:04.689945+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.541948 seconds", "timestamp": "2024-06-29T16:13:04.690160+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:13:06.478010+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 37068. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T16:13:06.480383+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3698.0 tokens", "timestamp": "2024-06-29T16:28:25.292307+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:28:27.750051+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 3405, 'output_tokens': 137, 'total_tokens': 3542}", "timestamp": "2024-06-29T16:28:27.756003+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 24184.0 tokens", "timestamp": "2024-06-29T16:28:30.599156+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:28:47.204869+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 22168, 'output_tokens': 1217, 'total_tokens': 23385}", "timestamp": "2024-06-29T16:28:47.221054+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 60865.75 tokens", "timestamp": "2024-06-29T16:30:47.509053+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:30:48.043180+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.915442 seconds", "timestamp": "2024-06-29T16:30:48.044569+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:30:49.215162+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.557475 seconds", "timestamp": "2024-06-29T16:30:49.215438+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:30:51.012977+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 61271. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T16:30:51.013412+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 36770.75 tokens", "timestamp": "2024-06-29T16:31:16.863734+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:31:17.217105+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.895710 seconds", "timestamp": "2024-06-29T16:31:17.218398+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:31:18.371657+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.573409 seconds", "timestamp": "2024-06-29T16:31:18.373526+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:31:20.161691+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 37062. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T16:31:20.163724+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2931.0 tokens", "timestamp": "2024-06-29T16:31:50.917878+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:31:53.171464+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 3032, 'output_tokens': 137, 'total_tokens': 3169}", "timestamp": "2024-06-29T16:31:53.176010+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3509.0 tokens", "timestamp": "2024-06-29T16:31:53.456378+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:31:56.148202+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 3400, 'output_tokens': 137, 'total_tokens': 3537}", "timestamp": "2024-06-29T16:31:56.153124+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 37628.0 tokens", "timestamp": "2024-06-29T16:31:56.675420+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:31:57.058330+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.779294 seconds", "timestamp": "2024-06-29T16:31:57.058714+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:31:58.199423+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.796139 seconds", "timestamp": "2024-06-29T16:31:58.200362+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:32:00.302090+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 37806. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T16:32:00.302478+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 41276.5 tokens", "timestamp": "2024-06-29T16:32:00.840462+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:32:01.319570+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.978927 seconds", "timestamp": "2024-06-29T16:32:01.319976+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:32:02.514817+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.516810 seconds", "timestamp": "2024-06-29T16:32:02.515303+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:32:04.248083+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 41401. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T16:32:04.248431+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3717.5 tokens", "timestamp": "2024-06-29T16:32:38.223767+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:32:42.019615+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 3616, 'output_tokens': 137, 'total_tokens': 3753}", "timestamp": "2024-06-29T16:32:42.023976+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1592.75 tokens", "timestamp": "2024-06-29T16:32:42.247689+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:32:44.574161+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1377, 'output_tokens': 137, 'total_tokens': 1514}", "timestamp": "2024-06-29T16:32:44.578452+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1972.75 tokens", "timestamp": "2024-06-29T16:32:44.764027+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:32:47.241692+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1771, 'output_tokens': 137, 'total_tokens': 1908}", "timestamp": "2024-06-29T16:32:47.247450+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1874.25 tokens", "timestamp": "2024-06-29T16:32:47.519147+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:32:49.799884+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1630, 'output_tokens': 137, 'total_tokens': 1767}", "timestamp": "2024-06-29T16:32:49.804783+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2459.0 tokens", "timestamp": "2024-06-29T16:32:50.043020+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:32:52.128509+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2567, 'output_tokens': 137, 'total_tokens': 2704}", "timestamp": "2024-06-29T16:32:52.131864+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 23438.5 tokens", "timestamp": "2024-06-29T16:32:52.612146+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:33:19.507030+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 24818, 'output_tokens': 1438, 'total_tokens': 26256}", "timestamp": "2024-06-29T16:33:19.530917+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 44909.75 tokens", "timestamp": "2024-06-29T16:33:41.466870+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:33:41.921933+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.803996 seconds", "timestamp": "2024-06-29T16:33:41.922359+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:33:42.960051+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.549274 seconds", "timestamp": "2024-06-29T16:33:42.960747+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:33:44.761631+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 45128. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T16:33:44.762501+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 46276.25 tokens", "timestamp": "2024-06-29T16:34:00.658524+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:34:01.376933+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.923866 seconds", "timestamp": "2024-06-29T16:34:01.378306+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:34:02.598726+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.940680 seconds", "timestamp": "2024-06-29T16:34:02.599919+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:34:04.855665+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 46519. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T16:34:04.856042+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 17321.5 tokens", "timestamp": "2024-06-29T16:34:23.281459+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:34:39.571466+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 16513, 'output_tokens': 1238, 'total_tokens': 17751}", "timestamp": "2024-06-29T16:34:39.605346+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 43063.25 tokens", "timestamp": "2024-06-29T16:34:44.716214+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:34:45.405856+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 0.935355 seconds", "timestamp": "2024-06-29T16:34:45.406216+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:34:46.544927+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Retrying request to /chat/completions in 1.907913 seconds", "timestamp": "2024-06-29T16:34:46.545575+00:00", "logger": "openai._base_client", "module": "_base_client", "function": "_retry_request", "line": 1047, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"", "timestamp": "2024-06-29T16:34:48.718115+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-auoaVTjD1KeMmDkPBKRg7Dyi on tokens per min (TPM): Limit 30000, Requested 43701. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "timestamp": "2024-06-29T16:34:48.718854+00:00", "logger": "__name__", "module": "routes", "function": "getCitation", "line": 83, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 24185.5 tokens", "timestamp": "2024-06-29T16:35:20.077088+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T16:35:36.072917+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 22168, 'output_tokens': 1127, 'total_tokens': 23295}", "timestamp": "2024-06-29T16:35:36.091520+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 605.25 tokens", "timestamp": "2024-06-29T20:48:09.130724+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:11.867270+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 479, 'output_tokens': 102, 'total_tokens': 581}", "timestamp": "2024-06-29T20:48:11.874102+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2939.5 tokens", "timestamp": "2024-06-29T20:48:22.571279+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:24.951726+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 3045, 'output_tokens': 150, 'total_tokens': 3195}", "timestamp": "2024-06-29T20:48:24.962145+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3517.5 tokens", "timestamp": "2024-06-29T20:48:25.209460+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:27.634885+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 3413, 'output_tokens': 150, 'total_tokens': 3563}", "timestamp": "2024-06-29T20:48:27.641139+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3695.25 tokens", "timestamp": "2024-06-29T20:48:28.293264+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:30.808437+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 3436, 'output_tokens': 150, 'total_tokens': 3586}", "timestamp": "2024-06-29T20:48:30.813540+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2208.5 tokens", "timestamp": "2024-06-29T20:48:30.982910+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:33.085007+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2101, 'output_tokens': 150, 'total_tokens': 2251}", "timestamp": "2024-06-29T20:48:33.091469+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2812.5 tokens", "timestamp": "2024-06-29T20:48:33.405169+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:35.280060+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2738, 'output_tokens': 141, 'total_tokens': 2879}", "timestamp": "2024-06-29T20:48:35.290416+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1601.25 tokens", "timestamp": "2024-06-29T20:48:35.461287+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:47.908844+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Failed to parse JSON from completion: Invalid json output: ```json\n{\n\"data\": {\n    \"Encodes omega-3 fatty acid desaturase enzyme.\": 0.5,\n    \"Enhances lipid retention in Nannochloropsis.\": 0.1,\n    \"Enhances lipid retention in Chlorella.\": 0.1,\n    \"Related to W-3 FAD gene.\": 0.2,\n    \"Filed information on W-3 FAD gene.\": 0.3,\n    \"Studied in micro algae.\": 0.2,\n    \"Associated with omega-3 fatty acids.\": 0.6,\n    \"Improves lipid profiles in algae.\": 0.1\n},\n}\n```", "timestamp": "2024-06-29T20:48:47.912916+00:00", "logger": "__name__", "module": "routes", "function": "extractSpecificPatentMetrics", "line": 57, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3106.75 tokens", "timestamp": "2024-06-29T20:48:48.125268+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:50.062593+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2941, 'output_tokens': 150, 'total_tokens': 3091}", "timestamp": "2024-06-29T20:48:50.065070+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2467.5 tokens", "timestamp": "2024-06-29T20:48:50.208049+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:52.824901+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2580, 'output_tokens': 150, 'total_tokens': 2730}", "timestamp": "2024-06-29T20:48:52.833243+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2571.75 tokens", "timestamp": "2024-06-29T20:48:52.978174+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:55.179961+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2219, 'output_tokens': 150, 'total_tokens': 2369}", "timestamp": "2024-06-29T20:48:55.186245+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1981.25 tokens", "timestamp": "2024-06-29T20:48:55.360590+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:48:57.023411+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1784, 'output_tokens': 150, 'total_tokens': 1934}", "timestamp": "2024-06-29T20:48:57.029145+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1601.25 tokens", "timestamp": "2024-06-29T20:51:23.094116+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:51:26.013003+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1390, 'output_tokens': 150, 'total_tokens': 1540}", "timestamp": "2024-06-29T20:51:26.015151+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1813.0 tokens", "timestamp": "2024-06-29T20:57:18.426231+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:57:26.396786+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2111, 'output_tokens': 530, 'total_tokens': 2641}", "timestamp": "2024-06-29T20:57:26.415760+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2488.0 tokens", "timestamp": "2024-06-29T20:57:26.796881+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:57:33.298350+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2570, 'output_tokens': 480, 'total_tokens': 3050}", "timestamp": "2024-06-29T20:57:33.314416+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2603.5 tokens", "timestamp": "2024-06-29T20:57:33.806297+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:57:40.685436+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2553, 'output_tokens': 517, 'total_tokens': 3070}", "timestamp": "2024-06-29T20:57:40.702133+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1123.5 tokens", "timestamp": "2024-06-29T20:57:41.461481+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:57:46.800505+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1211, 'output_tokens': 404, 'total_tokens': 1615}", "timestamp": "2024-06-29T20:57:46.808698+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1765.0 tokens", "timestamp": "2024-06-29T20:57:47.069343+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:57:52.014832+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1865, 'output_tokens': 442, 'total_tokens': 2307}", "timestamp": "2024-06-29T20:57:52.021826+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 519.5 tokens", "timestamp": "2024-06-29T20:57:52.250843+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:57:57.374586+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 509, 'output_tokens': 394, 'total_tokens': 903}", "timestamp": "2024-06-29T20:57:57.389465+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2093.25 tokens", "timestamp": "2024-06-29T20:57:57.686790+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:58:03.841283+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 2110, 'output_tokens': 454, 'total_tokens': 2564}", "timestamp": "2024-06-29T20:58:03.857353+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1403.0 tokens", "timestamp": "2024-06-29T20:58:04.140998+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:58:08.199798+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1715, 'output_tokens': 410, 'total_tokens': 2125}", "timestamp": "2024-06-29T20:58:08.213946+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1480.75 tokens", "timestamp": "2024-06-29T20:58:08.508701+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:58:14.694177+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 1333, 'output_tokens': 559, 'total_tokens': 1892}", "timestamp": "2024-06-29T20:58:14.707440+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 899.25 tokens", "timestamp": "2024-06-29T20:58:14.965510+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:58:18.177772+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 903, 'output_tokens': 293, 'total_tokens': 1196}", "timestamp": "2024-06-29T20:58:18.190119+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 605.25 tokens", "timestamp": "2024-06-29T21:06:11.767220+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 27, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T21:06:13.823599+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "{'input_tokens': 479, 'output_tokens': 110, 'total_tokens': 589}", "timestamp": "2024-06-29T21:06:13.828273+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 55, "thread_name": "MainThread"}
Started Up
=======
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-29T00:17:03.130973+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:17:04.549935+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1969.0 tokens", "timestamp": "2024-06-29T00:17:08.601482+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:17:10.488934+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "'ResourceProtector' object has no attribute 'get_token'", "timestamp": "2024-06-29T00:17:18.784799+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 36, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:18:07.705704+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:18:47.476223+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1920.75 tokens", "timestamp": "2024-06-29T00:18:56.097067+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:18:57.858576+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /save/patent [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 105, in decorated\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/developer/EasyIP/backend/app/blueprints/saved/routes.py\", line 23, in patent\n    token = require_auth.get_token()\n            ^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'ResourceProtector' object has no attribute 'get_token'", "timestamp": "2024-06-29T00:18:59.507279+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:19:51.448641+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:28:10.233827+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:28:37.696695+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:28:44.561453+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:28:48.822078+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:29:12.012798+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:29:19.606616+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:29:37.574888+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:29:40.746051+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:29:43.960271+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:29:52.579174+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /llm/extractSpecificPatentMetrics [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 98, in decorated\n    self.acquire_token(**claims)\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 69, in acquire_token\n    token = self.validate_request(request=request, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/oauth2/rfc6749/resource_protector.py\", line 139, in validate_request\n    validator.validate_token(token, scopes, request, **kwargs)\nTypeError: Auth0JWTBearerTokenValidator.validate_token() takes 3 positional arguments but 4 were given", "timestamp": "2024-06-29T00:30:01.352877+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /llm/extractSpecificPatentMetrics [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 98, in decorated\n    self.acquire_token(**claims)\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 69, in acquire_token\n    token = self.validate_request(request=request, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/oauth2/rfc6749/resource_protector.py\", line 139, in validate_request\n    validator.validate_token(token, scopes, request, **kwargs)\nTypeError: Auth0JWTBearerTokenValidator.validate_token() takes 3 positional arguments but 4 were given", "timestamp": "2024-06-29T00:30:02.919542+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /llm/extractSpecificPatentMetrics [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 98, in decorated\n    self.acquire_token(**claims)\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 69, in acquire_token\n    token = self.validate_request(request=request, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/oauth2/rfc6749/resource_protector.py\", line 139, in validate_request\n    validator.validate_token(token, scopes, request, **kwargs)\nTypeError: Auth0JWTBearerTokenValidator.validate_token() takes 3 positional arguments but 4 were given", "timestamp": "2024-06-29T00:30:03.607152+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /llm/extractSpecificPatentMetrics [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 98, in decorated\n    self.acquire_token(**claims)\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 69, in acquire_token\n    token = self.validate_request(request=request, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/oauth2/rfc6749/resource_protector.py\", line 139, in validate_request\n    validator.validate_token(token, scopes, request, **kwargs)\nTypeError: Auth0JWTBearerTokenValidator.validate_token() takes 3 positional arguments but 4 were given", "timestamp": "2024-06-29T00:30:04.290070+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /llm/extractSpecificPatentMetrics [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 98, in decorated\n    self.acquire_token(**claims)\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 69, in acquire_token\n    token = self.validate_request(request=request, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/oauth2/rfc6749/resource_protector.py\", line 139, in validate_request\n    validator.validate_token(token, scopes, request, **kwargs)\nTypeError: Auth0JWTBearerTokenValidator.validate_token() takes 3 positional arguments but 4 were given", "timestamp": "2024-06-29T00:30:04.889684+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /llm/extractSpecificPatentMetrics [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 98, in decorated\n    self.acquire_token(**claims)\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 69, in acquire_token\n    token = self.validate_request(request=request, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/oauth2/rfc6749/resource_protector.py\", line 139, in validate_request\n    validator.validate_token(token, scopes, request, **kwargs)\nTypeError: Auth0JWTBearerTokenValidator.validate_token() takes 3 positional arguments but 4 were given", "timestamp": "2024-06-29T00:30:05.451798+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /llm/extractSpecificPatentMetrics [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 98, in decorated\n    self.acquire_token(**claims)\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 69, in acquire_token\n    token = self.validate_request(request=request, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/oauth2/rfc6749/resource_protector.py\", line 139, in validate_request\n    validator.validate_token(token, scopes, request, **kwargs)\nTypeError: Auth0JWTBearerTokenValidator.validate_token() takes 3 positional arguments but 4 were given", "timestamp": "2024-06-29T00:30:05.992052+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:30:16.863102+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1851.75 tokens", "timestamp": "2024-06-29T00:30:17.372863+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:30:19.233262+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Saver.savePatent() missing 1 required positional argument: 'patentData'", "timestamp": "2024-06-29T00:30:21.019695+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 36, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:30:45.469505+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3965.25 tokens", "timestamp": "2024-06-29T00:30:48.592869+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:30:50.923555+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Saver.savePatent() missing 1 required positional argument: 'patentData'", "timestamp": "2024-06-29T00:30:52.391137+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 36, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:30:59.690744+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1943.0 tokens", "timestamp": "2024-06-29T00:31:00.151427+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:31:02.291517+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /save/patent [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 105, in decorated\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/developer/EasyIP/backend/app/blueprints/saved/routes.py\", line 25, in patent\n    print(\"CTX\", ctx)\n                 ^^^\nNameError: name 'ctx' is not defined", "timestamp": "2024-06-29T00:31:04.095604+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:31:17.000783+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:31:22.270712+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2138.0 tokens", "timestamp": "2024-06-29T00:31:23.059282+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:31:24.993409+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Saver.savePatent() missing 1 required positional argument: 'patentData'", "timestamp": "2024-06-29T00:31:26.780909+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 31, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:32:09.194720+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:32:28.207147+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:33:31.813092+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:33:36.093131+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:33:50.320169+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /llm/extractSpecificPatentMetrics [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 98, in decorated\n    self.acquire_token(**claims)\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 69, in acquire_token\n    token = self.validate_request(request=request, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/oauth2/rfc6749/resource_protector.py\", line 139, in validate_request\n    validator.validate_token(token, scopes, request, **kwargs)\nTypeError: Auth0JWTBearerTokenValidator.validate_token() takes 3 positional arguments but 4 were given", "timestamp": "2024-06-29T00:33:56.630985+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Exception on /llm/extractSpecificPatentMetrics [POST]\nTraceback (most recent call last):\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n    response = self.full_dispatch_request()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n    return cors_after_request(app.make_response(f(*args, **kwargs)))\n                                                ^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 98, in decorated\n    self.acquire_token(**claims)\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/integrations/flask_oauth2/resource_protector.py\", line 69, in acquire_token\n    token = self.validate_request(request=request, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/devk/Developer/EasyIP/backend/env/lib/python3.12/site-packages/authlib/oauth2/rfc6749/resource_protector.py\", line 139, in validate_request\n    validator.validate_token(token, scopes, request, **kwargs)\nTypeError: Auth0JWTBearerTokenValidator.validate_token() takes 3 positional arguments but 4 were given", "timestamp": "2024-06-29T00:33:58.140130+00:00", "logger": "app", "module": "app", "function": "log_exception", "line": 838, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:34:05.358918+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2613.75 tokens", "timestamp": "2024-06-29T00:34:05.946926+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:34:07.670666+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Received data: patentInfo=PatentInfo(abstract='A dual brewing mechanism is provided. The dual brewing mechanism includes a hot water pipe, an espresso brewing device, a first solenoid valve, a pour over device and a second solenoid valve. The espresso brewing device includes a brewing head that has a flow channel configured therein, and hot water can be transported to the flow channel through a first pipe body of the hot water pipe. The first solenoid valve is in communication with the flow channel of the espresso brewing device, the hot water is transported to the pour over device through the second pipe body of the hot water pipe, and the second solenoid valve is in communication with the pour over device.', alias='LIU', id='US20220039588A1', image='https://api.projectpq.ai/patents/US20220039588A1/thumbnails/1', index='A47J', inventors=['KUANG-YU LIU'], mapping=None, owner='GINO CREATION CO., LTD.', publication_date='2022-02-10', publication_id='US20220039588A1', score=0.15316814184188843, snippet=None, title='DUAL BREWING MECHANISM', type='patent', www_link='https://patents.google.com/patent/US20220039588A1/en') search='coffee machine' summary='' percentages={'Allows for customizable strength.': 0.3, 'Brews coffee.': 0.9, 'Can make cappuccinos.': 0.6, 'Can make espresso.': 1.0, 'Has auto shutoff feature.': 0.2, 'Has built-in grinder.': 0.1, 'Has milk frother.': 0.1, 'Has programmable settings.': 0.2} citations={}", "timestamp": "2024-06-29T00:34:09.375747+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 37, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:39:23.273062+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:39:27.923715+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:39:31.298794+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:39:36.472714+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:39:42.990737+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:39:48.391667+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:39:56.429576+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:40:01.857370+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:40:40.613901+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:40:44.911043+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:43:29.286120+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:51:44.076087+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:52:37.192411+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:52:48.870703+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:53:04.312969+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:53:10.111133+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2461.25 tokens", "timestamp": "2024-06-29T00:53:16.712848+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:53:18.444104+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Received data: patentInfo=PatentInfo(abstract='A beverage making machine where the main machine is located under the counter out of the view of the customers. This new design allows for the machine to be built in sections instead of inserting all components into one device and allows for easy servicing. Using electrically heated hoses allows for the main user interface to be located any distance away from the brewing machine, which frees up counter space and allows for easier servicing. The electrically heated hoses are a key component to this machine because the hose is electrically heated to maintain a desired temperature level so that heated fluids do not lose heat upon transfer from boiler to dispenser, making this machine a temperature stable coffee/espresso machine.', alias='Myers et al.', id='US20180014686A1', image='https://api.projectpq.ai/patents/US20180014686A1/thumbnails/1', index='A47J', inventors=['Michael Gregory Myers', 'Terrance David Ziniewicz'], mapping=None, owner='Assignee N/A', publication_date='2018-01-18', publication_id='US20180014686A1', score=0.1538107991218567, snippet=None, title='System and Method for Fluid Temperature Stability for Multi-Section Beverage Making Machine', type='patent', www_link='https://patents.google.com/patent/US20180014686A1/en') search='coffee machine' summary='' percentages={'Allows for customizable strength.': 0.3, 'Brews coffee.': 0.9, 'Can make cappuccinos.': 0.7, 'Can make espresso.': 0.9, 'Has auto shutoff feature.': 0.1, 'Has built-in grinder.': 0.1, 'Has milk frother.': 0.7, 'Has programmable settings.': 0.8} citations={}", "timestamp": "2024-06-29T00:53:20.295071+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 40, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:54:46.015771+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:54:52.520913+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:55:04.223498+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:55:10.528419+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:55:16.839608+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:55:24.271059+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:55:29.552000+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1915.0 tokens", "timestamp": "2024-06-29T00:55:31.980406+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:55:34.179070+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "'PatentData' object has no attribute 'patent_data'", "timestamp": "2024-06-29T00:55:37.662863+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 38, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:56:22.703534+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:56:33.335913+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 4686.5 tokens", "timestamp": "2024-06-29T00:56:34.714913+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:56:36.568034+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Failed to commit objects: (builtins.TypeError) Object of type PatentData is not JSON serializable\n[SQL: INSERT INTO public.saved_patent (user_id, organization_id, patent_data) VALUES (%(user_id)s, %(organization_id)s, %(patent_data)s) RETURNING public.saved_patent.id, public.saved_patent.saved_on]\n[parameters: [{'user_id': 'google-oauth2|108809862173138748904', 'patent_data': PatentData(patentInfo=PatentInfo(abstract='The automatic coffee machine (1) comprise ... (1780 characters truncated) ... ff feature.': 0.1, 'Has built-in grinder.': 0.1, 'Has milk frother.': 0.9, 'Has programmable settings.': 0.1}, citations={}), 'organization_id': None}]]", "timestamp": "2024-06-29T00:56:42.922011+00:00", "logger": "database.databaseCall", "module": "databaseCall", "function": "createAndCommit", "line": 44, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Failed to commit objects: (builtins.TypeError) Object of type PatentData is not JSON serializable\n[SQL: INSERT INTO public.saved_patent (user_id, organization_id, patent_data) VALUES (%(user_id)s, %(organization_id)s, %(patent_data)s) RETURNING public.saved_patent.id, public.saved_patent.saved_on]\n[parameters: [{'user_id': 'google-oauth2|108809862173138748904', 'patent_data': PatentData(patentInfo=PatentInfo(abstract='The automatic coffee machine (1) comprise ... (1780 characters truncated) ... ff feature.': 0.1, 'Has built-in grinder.': 0.1, 'Has milk frother.': 0.9, 'Has programmable settings.': 0.1}, citations={}), 'organization_id': None}]]", "timestamp": "2024-06-29T00:56:42.922283+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 38, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:57:04.842657+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:57:12.149060+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-29T00:57:16.483690+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:57:17.671536+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2990.25 tokens", "timestamp": "2024-06-29T00:57:24.501301+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:57:26.362510+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Received data: patentInfo=PatentInfo(abstract='A method for making cold brew coffee and a system for brewing cold brew coffee is described. A cold brew coffee device may include a water reservoir containing water, a plurality of tubes for transporting water in the water reservoir to a different location, a drip mechanism for receiving water from the water reservoir, a coffee grounds container for receiving water from the drip mechanism, a pump for pumping water from the water reservoir to the drip mechanism, a container for collecting coffee-infused water from the coffee grounds container, a user interface for displaying information and providing alerts, a controller for controlling the pump and user interface, and a battery for providing power to the controller, the pump, and the user interface.', alias='vonNieda et al.', id='US20210274967A1', image='https://api.projectpq.ai/patents/US20210274967A1/thumbnails/1', index='A47J', inventors=['Olivia vonNieda', 'Jackson Shuttleworth'], mapping=None, owner='Jova Coffee Company', publication_date='2021-09-09', publication_id='US20210274967A1', score=0.10189545154571533, snippet=None, title='SYSTEMS AND METHODS FOR AUTOMATED COLD DRIP COFFEE', type='patent', www_link='https://patents.google.com/patent/US20210274967A1/en') search='coffee machine' summary='' percentages={'Adjustable brewing strength.': 0.7, 'Auto shut-off feature.': 0.5, 'Brews coffee.': 0.8, 'Compatible with coffee pods.': 0.9, 'Dispenses hot water.': 0.3, 'Has a built-in grinder.': 0.2, 'Has a milk frother.': 0.2, 'Programmable timer for brewing.': 0.2} citations={}", "timestamp": "2024-06-29T00:57:28.234955+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 40, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:58:05.394955+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:58:36.783147+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:58:40.947193+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3016.0 tokens", "timestamp": "2024-06-29T00:58:49.255560+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T00:58:51.483173+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Received data: patentInfo=PatentInfo(abstract='A coffee machine is provided. The coffee machine may include an electronic control module configured to receive at least one flow set point and at least one temperature set point. The coffee machine may further include a portafilter, a group head configured to receive the portafilter, and at least one water line configured to supply water. The coffee machine may further include at least one syringe pump configured to pressurize the water to attain the at least one flow set point. The coffee machine may further include an in-line heating element configured to control temperature of the water according to the at least one temperature set point. The coffee machine may further include a feedback loop configured to provide the temperature to the electronic control module to enable selectively adjusting the temperature.', alias='Mohammad et al.', id='US11076715B1', image='https://api.projectpq.ai/patents/US11076715B1/thumbnails/1', index='A47J', inventors=['Ali H Mohammad', 'Ethan Miller'], mapping=None, owner='Nuli Coffee, Inc.', publication_date='2021-08-03', publication_id='US11076715B1', score=0.10414904356002808, snippet=None, title='Coffee machine with dynamic flow and temperature control', type='patent', www_link='https://patents.google.com/patent/US11076715B1/en') search='coffee machine' summary='' percentages={'Adjustable brewing strength.': 0.5, 'Auto shut-off feature.': 0.1, 'Brews coffee.': 0.7, 'Compatible with coffee pods.': 0.9, 'Dispenses hot water.': 0.1, 'Has a built-in grinder.': 0.1, 'Has a milk frother.': 0.3, 'Programmable timer for brewing.': 0.1} citations={}", "timestamp": "2024-06-29T00:58:53.306261+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 40, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T00:59:55.091044+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T19:38:08.269417+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T19:39:06.249136+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T19:39:12.344696+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T19:39:16.217478+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T19:39:21.385232+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T19:39:52.521926+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T20:22:51.346504+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-29T20:23:21.937838+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:23:23.340349+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T20:26:15.002184+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-29T20:29:06.275367+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:29:07.933587+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2342.25 tokens", "timestamp": "2024-06-29T20:29:14.889780+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:29:16.743358+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Received data: patentInfo=PatentInfo(abstract='Embodiments are directed towards regulating flow rate in an espresso machine, during a multi-phase brewing process which includes a pre-brew and an extraction phase. During the pre-brew phase, coffee grounds are slowly pre-wetted and/or out-gassed with a first volume of water delivered at a first flow rate. During the extraction phase, a second volume of water is delivered, at a second flow rate, to extract espresso, where the second volume is delivered at a generally greater pressure than the first volume. The second flow rate is greater than the first flow rate. The flow rates, volumes, and pressures are regulated by the espresso machine, which includes a flow rate regulation assembly that includes first and second flow paths and first and second valves. Baristas may vary the flow rate, volume, and pressure of water throughout the brewing process by opening, closing, or otherwise adjusting at least one of the valves.', alias='Prefontaine', id='US9364117B2', image='https://api.projectpq.ai/patents/US9364117B2/thumbnails/1', index='A23F', inventors=['Jason Camille Prefontaine'], mapping=None, owner='Seattle Espresso Machine Corporation', publication_date='2016-06-14', publication_id='US9364117B2', score=0.18412911891937256, snippet=None, title='Method for regulating flow rate in an espresso machine', type='patent', www_link='https://patents.google.com/patent/US9364117B2/en') search='coffee machine' summary='' percentages={'Adjustable brew strength.': 0.9, 'Brews coffee.': 0.8, 'Built-in grinder for fresh beans.': 0.2, 'Detachable parts for easy cleaning.': 0.5, 'Has a water filter for pure coffee.': 0.1, 'Makes espresso.': 0.7, 'Milk frother for cappuccinos.': 0.2, 'Programmable for automatic brewing.': 0.8} citations={}", "timestamp": "2024-06-29T20:29:19.692789+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 40, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 540.75 tokens", "timestamp": "2024-06-29T20:37:57.557247+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:37:59.073997+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2676.5 tokens", "timestamp": "2024-06-29T20:38:04.078962+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T20:38:06.149722+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Received data: patentInfo=PatentInfo(abstract='Method for cultivating paralarvae of the common octopus, Octopusvulgaris up to the settlement thereof (benthic phase), based on a diet of prey containing the caprellids Pfttisica marina and CaprelIa equilibra and/or gammarids of the genus Jassa spp. Factors such as light conditions, water renewal and temperature, inter alia, are optimized to obtain maximum paralarvae survival.', alias='ESTRADA et al.', id='US20200367476A1', image='https://api.projectpq.ai/patents/US20200367476A1/thumbnails/1', index='A01K', inventors=['Ricardo TUR ESTRADA', 'Pedro Miguel RODRIGUES DOS SANTOS DOMING', 'Eduardo ALMANSA BERRO', 'Maria LAGO ROUCO', 'Pablo GARCIA FERNANDEZ', 'Evaristo PEREZ RIAL'], mapping=None, owner='INSTITUTO ESPANOL DE OXCEANOGRAFEA', publication_date='2020-11-26', publication_id='US20200367476A1', score=0.24012655019760132, snippet=None, title='METHOD FOR CULTIVATING PARALARVAE OF THE COMMON OCTOPUS, OCTOPUS VULGARIS', type='patent', www_link='https://patents.google.com/patent/US20200367476A1/en') search='dinosaur' summary='' percentages={'Carnivorous, herbivorous, or omnivorous diet based on the species.': 0.1, 'Covered in scales or feathers depending on the species.': 0.1, 'Extinct reptile species that lived millions of years ago.': 0.1, 'Fossils of dinosaurs are found worldwide.': 0.2, 'Lived during different time periods like Triassic, Jurassic, and Cretaceous.': 0.2, 'Some had sharp teeth for hunting prey.': 0.3, 'Varied in sizes from small to huge creatures.': 0.2, 'Walked on two or four legs depending on the species.': 0.1} citations={}", "timestamp": "2024-06-29T20:38:08.772465+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 40, "thread_name": "MainThread"}
{"level": "ERROR", "message": "(psycopg2.OperationalError) SSL connection has been closed unexpectedly\n\n[SQL: SELECT public.reg_user.id AS public_reg_user_id, public.reg_user.first_name AS public_reg_user_first_name, public.reg_user.last_name AS public_reg_user_last_name, public.reg_user.email AS public_reg_user_email, public.reg_user.subscription_type AS public_reg_user_subscription_type \nFROM public.reg_user \nWHERE public.reg_user.id = %(pk_1)s]\n[parameters: {'pk_1': 'google-oauth2|108809862173138748904'}]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "timestamp": "2024-06-29T20:49:20.735145+00:00", "logger": "__name__", "module": "routes", "function": "fetchPatents", "line": 60, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T20:53:43.530854+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T20:53:46.636586+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T20:53:50.815339+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T21:01:27.410103+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T21:01:48.267148+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "(psycopg2.OperationalError) SSL connection has been closed unexpectedly\n\n[SQL: SELECT public.reg_user.id AS public_reg_user_id, public.reg_user.first_name AS public_reg_user_first_name, public.reg_user.last_name AS public_reg_user_last_name, public.reg_user.email AS public_reg_user_email, public.reg_user.subscription_type AS public_reg_user_subscription_type \nFROM public.reg_user \nWHERE public.reg_user.id = %(pk_1)s]\n[parameters: {'pk_1': 'google-oauth2|108809862173138748904'}]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "timestamp": "2024-06-29T21:18:21.542578+00:00", "logger": "__name__", "module": "routes", "function": "fetchPatents", "line": 59, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 540.0 tokens", "timestamp": "2024-06-29T21:37:34.540232+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T21:37:36.079375+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 2447.5 tokens", "timestamp": "2024-06-29T21:37:48.202034+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T21:37:50.105938+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 9524.0 tokens", "timestamp": "2024-06-29T21:37:54.116385+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T21:38:10.379184+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Received data: patentInfo=PatentInfo(abstract='A cutting tool with a ruler connected to a track, a cutting device moveable along the track and a sharpening element positioned on the track. The cutting device includes a blade that contacts the sharpening element to sharpen the blade.', alias='Zaremski', id='US20160214268A1', image='https://api.projectpq.ai/patents/US20160214268A1/thumbnails/1', index='B26D', inventors=['Mark Zaremski'], mapping=None, owner='Mark Zaremski', publication_date='2016-07-28', publication_id='US20160214268A1', score=0.19165074825286865, snippet=None, title='SHARPENING ELEMENT FOR A CUTTING DEVICE', type='patent', www_link='https://patents.google.com/patent/US20160214268A1/en') search='razor' summary='' percentages={'Can be used for precise cutting.': 0.5, 'Can be used for shaving.': 0.1, 'Comes with a protective cover.': 0.3, 'Compact and portable design.': 0.4, 'Easy to grip handle.': 0.6, 'Has replaceable blades.': 0.7, 'Must be handled carefully to avoid injuries.': 0.8, 'Sharpens blades.': 0.9} citations={}", "timestamp": "2024-06-29T21:38:10.647948+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 40, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1717.0 tokens", "timestamp": "2024-06-29T21:38:11.119459+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T21:38:13.145348+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Received data: patentInfo=PatentInfo(abstract='A cutting tool with a ruler connected to a track, a cutting device moveable along the track and a sharpening element positioned on the track. The cutting device includes a blade that contacts the sharpening element to sharpen the blade.', alias='Zaremski', id='US20160214268A1', image='https://api.projectpq.ai/patents/US20160214268A1/thumbnails/1', index='B26D', inventors=['Mark Zaremski'], mapping=None, owner='Mark Zaremski', publication_date='2016-07-28', publication_id='US20160214268A1', score=0.19165074825286865, snippet=None, title='SHARPENING ELEMENT FOR A CUTTING DEVICE', type='patent', www_link='https://patents.google.com/patent/US20160214268A1/en') search='razor' summary='' percentages={'Can be used for precise cutting.': 0.5, 'Can be used for shaving.': 0.1, 'Comes with a protective cover.': 0.3, 'Compact and portable design.': 0.4, 'Easy to grip handle.': 0.6, 'Has replaceable blades.': 0.7, 'Must be handled carefully to avoid injuries.': 0.8, 'Sharpens blades.': 0.9} citations={'Compact and portable design.': Citations(abstract=[], claims=[HighlightedText(before='A cutting tool comprising: a ruler; a track connected along an edge of the ruler; a sharpening element positioned on the track; and a cutting device slideable along the track, the cutting device including a blade and wherein the cutting device cuts a material positioned under the cutting tool by pressing downward on the cutting device towards the material and sliding the cutting device along the track while sharpening a portion of the blade in contact with the sharpening element.', highlight='wherein the cutting device includes a spring to bias the cutting device upward.', after='The cutting tool of claim 2, wherein the sharpening element extends along a lower edge of the track and the blade is sharpened by sliding the blade along the sharpening element.'), HighlightedText(before='A cutting tool comprising: a ruler including a rectangular shape with markings for aligning a material to be cut; a track connected along an edge of the ruler; a sharpening element positioned on the track; and a cutting device positioned on and slideable along the track, the cutting device including a blade and a spring, wherein the cutting device operates in an engaged position and a retracted position, wherein in the engaged position the cutting device is pressed downward with a portion of the blade extending below a bottom surface of the cutting tool and the spring is in a tensioned state and the cutting device slides along the track to cut the material and wherein in the retracted position the blade is above the bottom surface and the spring is in an untensioned state and the blade is in contact with the sharpening element.', highlight='wherein in the engaged position the cutting device slides along the track to cut the material.', after='The cutting tool of claim 9, wherein the sharpening element extends along a lower edge of the track and the blade is sharpened by sliding the blade along the sharpening element.'), HighlightedText(before='A cutting tool comprising: a ruler including a rectangular shape with markings for aligning a material to be cut; a track connected along an edge of the ruler; a sharpening element positioned on the track; and a cutting device positioned on and slideable along the track, the cutting device including a blade and a spring, wherein the cutting device includes an engaged position and a retracted position; wherein in the engaged position the cutting device is pressed downward with a portion of the blade extending below a bottom surface of the cutting tool and the spring is in a tensioned state and the cutting device may be slid along the track to cut the material while simultaneously sharpening a portion of the blade on the sharpening element; and wherein in the retracted position the blade is above the bottom surface and the spring is in an untensioned state and the blade does not contact the sharpening element.', highlight='wherein the blade is a rotatable disc with a sharpened outer circumference.', after='The cutting tool of claim 17, wherein the sharpening element includes at least one of tungsten carbide and diamond powder.')], description=[HighlightedText(before='FIGS. 7-15 show a cutting tool 110 according to another embodiment of this invention. As shown in FIG. 7, the cutting tool 110, also referred to as a ruler cutter, of this invention includes a ruler 112 connected to a track 114 along an edge of the ruler 112 and a sharpening element 116 positioned along a lower portion of the track 114.', highlight='In accordance with the invention, an elongate sharpening element extends along the cutting edge such that the cutting blade also progressively contacts the sharpening element for sharpening the blade as it is advanced across the table to make each cut.', after='In accordance with another embodiment, a cutting device of this invention comprises a ruler having a base and a cutting blade that runs along an edge of the base and may be depressed to cut a material positioned under the base. The cutting device further including an elongate sharpening element extending along the edge of cutting device such that the cutting blade also progressively contacts the sharpening element for sharpening the blade as it is advanced across the table to make each cut.'), HighlightedText(before='As shown in FIG. 7, the cutting tool 110, also referred to as a ruler cutter, of this invention includes a ruler 112 connected to a track 114 along an edge of the ruler 112 and a sharpening element 116 positioned along a lower portion of the track 114.', highlight='In a preferred embodiment, the ruler is manufactured from a durable acrylic clear plastic with markings for measuring and lining up a material to be cut.', after='In a preferred embodiment, the planar ruler includes non-slip grips to prevent the cutting ruler 110 from moving during a cut.')])}", "timestamp": "2024-06-29T21:38:13.288254+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 40, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 540.25 tokens", "timestamp": "2024-06-29T21:39:20.878603+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T21:39:22.061739+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T22:06:48.070735+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T22:08:54.612778+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.5 tokens", "timestamp": "2024-06-29T22:09:34.186876+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T22:09:35.225448+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1856.5 tokens", "timestamp": "2024-06-29T22:09:39.999540+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T22:09:41.732354+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Received data: patentInfo=PatentInfo(abstract='An espresso machine is constructed and programmed to have secondary water system. The secondary water supply works in conjunction with the coffee brewing mechanisms of the device to produce and Americano style coffee beverage. The size and strength of the resulting beverage may be pre-set, or user programmable.', alias='Grassia', id='US9924828B2', image='https://api.projectpq.ai/patents/US9924828B2/thumbnails/1', index='A47J', inventors=['Robert Grassia'], mapping=None, owner='Breville Pty Limited', publication_date='2018-03-27', publication_id='US9924828B2', score=0.07556456327438354, snippet=None, title='Espresso machine with Americano feature', type='patent', www_link='https://patents.google.com/patent/US9924828B2/en') search='Coffee machine.' summary='' percentages={'Alerts user when done.': 0.1, 'Brews hot beverage.': 0.8, 'Can use coffee beans.': 0.8, 'Can use coffee pods.': 0.9, 'Dispenses milk.': 0.1, 'Has electric screen for use.': 0.1, 'Has grate to prevent spillage.': 0.1, 'Has refillable water reservoir.': 0.3} citations={}", "timestamp": "2024-06-29T22:09:43.698890+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 40, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-29T22:09:53.254848+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T22:09:54.540879+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1856.25 tokens", "timestamp": "2024-06-29T22:09:58.060631+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T22:09:59.786100+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Failed to commit objects: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"uq_user_patent\"\nDETAIL:  Key (user_id, patent_id)=(google-oauth2|108809862173138748904, US9924828B2) already exists.\n\n[SQL: INSERT INTO public.saved_patent (user_id, organization_id, patent_id, patent_data) VALUES (%(user_id)s, %(organization_id)s, %(patent_id)s, %(patent_data)s) RETURNING public.saved_patent.id, public.saved_patent.saved_on]\n[parameters: {'user_id': 'google-oauth2|108809862173138748904', 'organization_id': None, 'patent_id': 'US9924828B2', 'patent_data': '{\"patentInfo\": {\"abstract\": \"An espresso machine is constructed and programmed to have secondary water system. The secondary water supply works in co ... (846 characters truncated) ... : 0.1, \"Can make espresso.\": 1.0, \"Dispenses hot water.\": 0.8, \"Has built-in grinder.\": 0.1, \"Programmable brewing settings.\": 0.4}, \"citations\": {}}'}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)", "timestamp": "2024-06-29T22:10:01.661385+00:00", "logger": "database.databaseCall", "module": "databaseCall", "function": "createAndCommit", "line": 44, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Failed to commit objects: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"uq_user_patent\"\nDETAIL:  Key (user_id, patent_id)=(google-oauth2|108809862173138748904, US9924828B2) already exists.\n\n[SQL: INSERT INTO public.saved_patent (user_id, organization_id, patent_id, patent_data) VALUES (%(user_id)s, %(organization_id)s, %(patent_id)s, %(patent_data)s) RETURNING public.saved_patent.id, public.saved_patent.saved_on]\n[parameters: {'user_id': 'google-oauth2|108809862173138748904', 'organization_id': None, 'patent_id': 'US9924828B2', 'patent_data': '{\"patentInfo\": {\"abstract\": \"An espresso machine is constructed and programmed to have secondary water system. The secondary water supply works in co ... (846 characters truncated) ... : 0.1, \"Can make espresso.\": 1.0, \"Dispenses hot water.\": 0.8, \"Has built-in grinder.\": 0.1, \"Programmable brewing settings.\": 0.4}, \"citations\": {}}'}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)", "timestamp": "2024-06-29T22:10:01.662429+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 38, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 9220.75 tokens", "timestamp": "2024-06-29T22:10:07.693993+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T22:10:13.424788+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Failed to commit objects: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"uq_user_patent\"\nDETAIL:  Key (user_id, patent_id)=(google-oauth2|108809862173138748904, US9924828B2) already exists.\n\n[SQL: INSERT INTO public.saved_patent (user_id, organization_id, patent_id, patent_data) VALUES (%(user_id)s, %(organization_id)s, %(patent_id)s, %(patent_data)s) RETURNING public.saved_patent.id, public.saved_patent.saved_on]\n[parameters: {'user_id': 'google-oauth2|108809862173138748904', 'organization_id': None, 'patent_id': 'US9924828B2', 'patent_data': '{\"patentInfo\": {\"abstract\": \"An espresso machine is constructed and programmed to have secondary water system. The secondary water supply works in co ... (2810 characters truncated) ...  reference to specific examples, but it will be appreciated by those skilled in the art that the invention may be embodied in many other forms.\"}]}}}'}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)", "timestamp": "2024-06-29T22:10:13.791701+00:00", "logger": "database.databaseCall", "module": "databaseCall", "function": "createAndCommit", "line": 44, "thread_name": "MainThread"}
{"level": "ERROR", "message": "Failed to commit objects: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"uq_user_patent\"\nDETAIL:  Key (user_id, patent_id)=(google-oauth2|108809862173138748904, US9924828B2) already exists.\n\n[SQL: INSERT INTO public.saved_patent (user_id, organization_id, patent_id, patent_data) VALUES (%(user_id)s, %(organization_id)s, %(patent_id)s, %(patent_data)s) RETURNING public.saved_patent.id, public.saved_patent.saved_on]\n[parameters: {'user_id': 'google-oauth2|108809862173138748904', 'organization_id': None, 'patent_id': 'US9924828B2', 'patent_data': '{\"patentInfo\": {\"abstract\": \"An espresso machine is constructed and programmed to have secondary water system. The secondary water supply works in co ... (2810 characters truncated) ...  reference to specific examples, but it will be appreciated by those skilled in the art that the invention may be embodied in many other forms.\"}]}}}'}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)", "timestamp": "2024-06-29T22:10:13.791967+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 38, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-29T22:10:34.265128+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T22:10:35.311775+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 3013.25 tokens", "timestamp": "2024-06-29T22:10:45.118204+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-29T22:10:47.343492+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "Received data: patentInfo=PatentInfo(abstract='A coffee machine is provided. The coffee machine may include an electronic control module configured to receive at least one flow set point and at least one temperature set point. The coffee machine may further include a portafilter, a group head configured to receive the portafilter, and at least one water line configured to supply water. The coffee machine may further include at least one syringe pump configured to pressurize the water to attain the at least one flow set point. The coffee machine may further include an in-line heating element configured to control temperature of the water according to the at least one temperature set point. The coffee machine may further include a feedback loop configured to provide the temperature to the electronic control module to enable selectively adjusting the temperature.', alias='Mohammad et al.', id='US11076715B1', image='https://api.projectpq.ai/patents/US11076715B1/thumbnails/1', index='A47J', inventors=['Ali H Mohammad', 'Ethan Miller'], mapping=None, owner='Nuli Coffee, Inc.', publication_date='2021-08-03', publication_id='US11076715B1', score=0.09821581840515137, snippet=None, title='Coffee machine with dynamic flow and temperature control', type='patent', www_link='https://patents.google.com/patent/US11076715B1/en') search='coffee machine' summary='' percentages={'Adjustable brewing strength.': 0.8, 'Brews coffee.': 0.95, 'Can make espresso.': 0.9, 'Compatible with coffee pods.': 0.9, 'Has milk frother.': 0.1, 'Has water filtration system.': 0.1, 'Programmable timer.': 0.1, 'Self-cleaning feature.': 0.1} citations={}", "timestamp": "2024-06-29T22:10:48.829969+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 40, "thread_name": "MainThread"}
{"level": "ERROR", "message": "(psycopg2.OperationalError) SSL connection has been closed unexpectedly\n\n[SQL: SELECT public.reg_user.id AS public_reg_user_id, public.reg_user.first_name AS public_reg_user_first_name, public.reg_user.last_name AS public_reg_user_last_name, public.reg_user.email AS public_reg_user_email, public.reg_user.subscription_type AS public_reg_user_subscription_type \nFROM public.reg_user \nWHERE public.reg_user.id = %(pk_1)s]\n[parameters: {'pk_1': 'google-oauth2|108809862173138748904'}]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "timestamp": "2024-06-29T22:27:45.117202+00:00", "logger": "__name__", "module": "routes", "function": "fetchPatents", "line": 59, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T22:37:25.191148+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T22:37:34.277657+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-29T22:40:10.080619+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "INFO", "message": "Started Up", "timestamp": "2024-06-30T06:19:51.808756+00:00", "logger": "__name__", "module": "run", "function": "<module>", "line": 24, "thread_name": "MainThread"}
{"level": "ERROR", "message": "(psycopg2.OperationalError) SSL connection has been closed unexpectedly\n\n[SQL: SELECT public.reg_user.id AS public_reg_user_id, public.reg_user.first_name AS public_reg_user_first_name, public.reg_user.last_name AS public_reg_user_last_name, public.reg_user.email AS public_reg_user_email, public.reg_user.subscription_type AS public_reg_user_subscription_type \nFROM public.reg_user \nWHERE public.reg_user.id = %(pk_1)s]\n[parameters: {'pk_1': 'google-oauth2|108809862173138748904'}]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "timestamp": "2024-06-30T06:30:19.740629+00:00", "logger": "__name__", "module": "routes", "function": "fetchPatents", "line": 59, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-30T06:32:21.426912+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-30T06:32:22.698175+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1616.75 tokens", "timestamp": "2024-06-30T06:32:26.793347+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-30T06:32:28.381524+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "(psycopg2.OperationalError) SSL connection has been closed unexpectedly\n\n[SQL: SELECT public.reg_user.id AS public_reg_user_id, public.reg_user.first_name AS public_reg_user_first_name, public.reg_user.last_name AS public_reg_user_last_name, public.reg_user.email AS public_reg_user_email, public.reg_user.subscription_type AS public_reg_user_subscription_type \nFROM public.reg_user \nWHERE public.reg_user.id = %(pk_1)s]\n[parameters: {'pk_1': 'google-oauth2|108809862173138748904'}]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "timestamp": "2024-06-30T06:40:48.808973+00:00", "logger": "__name__", "module": "routes", "function": "fetchPatents", "line": 59, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 542.25 tokens", "timestamp": "2024-06-30T06:50:26.361637+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-30T06:50:27.502918+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "INFO", "message": "This request used about 1616.75 tokens", "timestamp": "2024-06-30T06:50:31.382121+00:00", "logger": "__name__", "module": "llmRequests", "function": "makeRequest", "line": 26, "thread_name": "MainThread"}
{"level": "INFO", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "timestamp": "2024-06-30T06:50:32.972520+00:00", "logger": "httpx", "module": "_client", "function": "_send_single_request", "line": 1026, "thread_name": "MainThread"}
{"level": "ERROR", "message": "(psycopg2.OperationalError) SSL connection has been closed unexpectedly\n\n[SQL: SELECT public.reg_user.id AS public_reg_user_id, public.reg_user.first_name AS public_reg_user_first_name, public.reg_user.last_name AS public_reg_user_last_name, public.reg_user.email AS public_reg_user_email, public.reg_user.subscription_type AS public_reg_user_subscription_type \nFROM public.reg_user \nWHERE public.reg_user.id = %(pk_1)s]\n[parameters: {'pk_1': 'google-oauth2|108809862173138748904'}]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "timestamp": "2024-06-30T06:50:34.477325+00:00", "logger": "__name__", "module": "routes", "function": "patent", "line": 38, "thread_name": "MainThread"}
>>>>>>> development
